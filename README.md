# Manchester Robotics Challenge

<p align="justify">
Main project developed in collaboration with Manchester Robotics, as part of the undergraduate courses <strong>"Robotics Foundation"</strong> and <strong>"Intelligent Robotics Implementation."</strong>
</p>

## First Stage – ROS2 Brushed DC Motor Control (Robotics Foundation Course)

<p align="justify">
The goal was to control the speed of a brushed DC motor attached to one of the wheels of the Puzzlebot — Manchester Robotics’ educational, differential-drive mobile robot.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/6fedd6d5-7e08-441c-bdd8-1f1e3c2dfc30" alt="ROS2 DC Motor Control Layout" width="50%"/>
</p>

<p align="justify">
Although velocity control for the Puzzlebot’s wheels will later use pre-built facilities provided by Manchester Robotics, it is essential to first understand the core control principles.
</p>

<p align="justify">
One approach is open-loop control, where voltage is applied in proportion to the desired speed. However, this method may not be robust enough, since it lacks self-correction.
</p>

<p align="justify">
For this reason, a closed-loop controller was used: a PID. By applying proportional, integral, and derivative terms, the system can reduce error over time. This ensures that the actual speed converges to the desired value.
</p>

<p align="justify">
ROS 2 was used as the middleware to modularize and standardize the robotics software. In other words, it enables the development of a more organized and maintainable system.
</p>

### Methodology

#### Signal Processing

<p align="justify">
Initially, two prototype nodes were created to test ROS2 functionality. The first node generated a sinusoidal signal, and the second acted as a signal processor. It subscribed to the signal generated by the first node, modified it, and published the processed signal. Both signals were visualized using <code>rqt_plot</code>.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/a3c9a370-571c-4d43-af84-e51f3c0f7135" alt="signal_processing system" width="600"/>
</p>

<p align="justify">
To implement this:
</p>

<p align="justify">
1. A ROS2 package named <code>signal_processing</code> was created.<br>
2. Inside this package, the <code>signal_generator</code> node was developed. It used <code>math.sin()</code> and a time variable <code>t</code> that incremented on each callback to compute a sinusoidal wave. The resulting signal was published on the <code>/signal</code> topic.<br>
3. Next, the <code>signal_processor</code> node was implemented. It subscribed to the <code>/signal</code> topic and applied modifications to the incoming signal: a phase shift (using a trigonometric identity), reduced amplitude, and an offset. The processed signal was then published to its own topic <code>/proc_signal</code>.<br>
4. A launch file was added to start both nodes and open <code>rqt_plot</code> for signal visualization.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/28615f98-54db-4918-b63d-d1fafd96970a" alt="rqt_graph of the signal_processing system" width="600"/>
</p>

<p align="justify">
After building the package, the full system can be launched with:
</p>

```bash
ros2 launch signal_processing signal_processing.launch.py
```

#### Simulated Motor Control

<p align="justify">
The <code>signal_generator</code> node later evolved into the <code>setpoint</code> node for a simulated PID control system. The simulation included three main nodes:
</p>

<p align="justify">
- <code>setpoint</code>: published speed references.<br>
- <code>controller</code>: subscribed to both the setpoint and simulated motor output, computed the error, applied the PID algorithm, and published the control signal.<br>
- <code>dc_motor</code>: simulated motor dynamics using a first-order model, received the control input, updated the speed, and published feedback.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/433dc63e-382e-4a93-b062-9bd50e7500eb" alt="rqt_graph of the motor_control system" width="600"/>
</p>

<p align="justify">
The code was updated to load node parameters directly from the launch file and to allow real-time tuning using <code>rqt_reconfigure</code>.
</p>

<p align="justify">
The reference node was extended to support both sinusoidal and square wave signals. The signal type can also be changed in real time through dynamic configuration.
</p>

<p align="justify">
A new launch file was created to start three sets of motor controllers. To improve robustness, node execution order was managed using services, following this sequence:
</p>

<p align="justify">
1. <code>dc_motor</code><br>
2. <code>controller</code><br>
3. <code>setpoint</code>
</p>

<p align="justify">
After building the package, the full system can be launched with:
</p>

```bash
ros2 launch motor_control motor_control.launch.py 
```

<p align="justify">
This setup allowed experimentation with PID parameters and performance evaluation before working with real hardware.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/5dd26548-e3d3-464a-b33a-4fd6420e2c73" alt="rqt_graph of the motor_control system" width="600"/>
</p>

#### Real-World Motor Control

<p align="justify">
In the hardware phase, the <code>setpoint</code> node ran on a PC and is located in the <code>motor_control_real</code> package. The <code>motor</code> node was implemented on an ESP32 microcontroller using micro-ROS. This node handled the full control loop. Its code can be found in the <code>micro_ROS</code> folder.
</p>

<p align="justify">
The ESP32 used interrupts to read signals from a quadrature encoder and calculate the motor’s angular velocity. The <code>motor</code> node subscribed to the <code>setpoint</code> topic to receive the target speed from the PC. It then computed the error between the reference and the measured velocity, applied the PID algorithm to calculate the control output, and converted this into a PWM signal sent to the H-bridge to drive the motor.
</p>

<p align="justify">
To support system monitoring, the <code>motor</code> node also published key data through dedicated topics: the encoder count, measured angular velocity, error value, and the applied control signal.
</p>

### Control Strategy

<p align="justify">
Angular velocity is measured using a quadrature encoder mounted on the motor shaft. Hardware interrupts capture changes in the encoder channels. The velocity is computed by counting encoder pulses over a fixed time interval. With a resolution of 12 pulses per motor shaft revolution and a 35:1 gear reduction ratio, the pulses are converted into radians per second at the output shaft. The final value is multiplied by 2 to account for full quadrature decoding.
</p>

<p align="justify">
To improve signal quality, which can be affected by noise, a low-pass filter is applied. This filter reduces high-frequency components—where abrupt changes in the signal appear—without significantly affecting response time. By attenuating these high frequencies and preserving the lower ones, the filtered signal more accurately represents the actual output of the system.
</p>

<p align="justify">
The PID controller is implemented in discrete form. The result is a control output that we feed as a PWM signal into a motor driver. The driver then provides a voltage to the motor, influencing its angular velocity. We measure this new velocity, closing the loop. Depending on the sign of the control signal, the motor driver also adjusts the motor’s direction. The entire system operates in a closed-loop control cycle running at a constant frequency of 50 Hz.
</p>

### ROS2 Tools

<p align="justify">
The <code>setpoint</code> node publishes reference signals using configurable parameters: timer period, amplitude, and frequency. It supports multiple waveform types—such as sine, square, or step—and can either hold a fixed waveform or cycle through several. All parameters can be updated dynamically at runtime.
</p>

<p align="justify">
Quality of Service (QoS) settings were configured to ensure appropriate communication. The <code>setpoint</code> node used the <code>RELIABLE</code> policy to guarantee that reference signals consistently reached the <code>motor</code> node, as these signals are critical for controlling a real-world system and must not be lost. On the other hand, the <code>motor</code> node used the <code>BEST_EFFORT</code> policy for non-critical data, such as debugging messages, where occasional packet loss is acceptable. This choice also helps reduce communication latency.
</p>

<p align="justify">
In addition, a state machine was implemented to establish and maintain the connection with the micro-ROS agent. In case of disconnection, it attempts to reconnect and reinitialize ROS 2 entities.
</p>

### PID Tuning Strategy

<p align="justify">
To tune the PID, a manual approach was used, where gains were adjusted through trial and error until the system responded satisfactorily. This process was not just guesswork; it followed the following general methodology:
</p>

<p align="justify">
The process began with a pure P controller. The proportional gain scales the error, so increasing the P value makes the system reach the setpoint faster. However, if the P gain is too high, it can cause oscillations.
</p>

<p align="justify">
The integral term was then added to eliminate steady-state error, helping the system reach and maintain the desired reference over time.
</p>

<p align="justify">
Finally, the derivative term was introduced. D-action provides damping but is highly sensitive to noise. Rapid changes in the signal generate large derivative values, which can amplify measurement noise. Due to the presence of noise in the setup, the D term was applied conservatively.
</p>

### Sampling Time

<p align="justify">
The sampling time is set to 50 Hz. In theory, a higher sampling frequency allows the controller to respond more effectively, as it receives more frequent updates about the system’s behavior. However, using ROS introduces overhead that is not present in basic microcontroller setups.
</p>

<p align="justify">
In this case, the system is limited by the executor's spin time, which also processes incoming setpoint data from the teleoperator. As a result, the controller cannot operate at a frequency higher than the rate at which new setpoint values can be reliably received.
</p>

### PWM Frequency

<p align="justify">
Choosing an appropriate PWM frequency can significantly improve the performance and control of brushed DC motors. When calculating the equivalent voltage delivered by PWM, it is often assumed that the motor responds as if connected to a constant voltage source. However, this is not the case.
</p>

<p align="justify">
The rotor of a brushed DC motor consists of coils of wire wound around a laminated magnetic core, which makes it behave as an inductor. Inductors are electromagnetic components that accumulate energy through a gradually increasing magnetic field generated by current passing through the coil. Depending on the coil size, it may take several milliseconds to accumulate enough energy to rotate the shaft.
</p>

<p align="justify">
Because of this inductive behavior, DC motors perform best when the applied voltage is relatively constant, giving the magnetic field time to build up. At higher PWM frequencies, the pulses switch too quickly for the coil to gather sufficient energy, which can prevent the motor from spinning effectively.
</p>

<p align="justify">
Lowering the PWM frequency allows the motor coils to draw more energy from each pulse. This helps the motor start spinning at lower equivalent voltages and improves torque at low speeds. The goal is to select a frequency that provides good torque across the desired speed range while minimizing the vibration that can occur at lower frequencies.
</p>

<p align="justify">
As a general rule, most small brushed DC motors perform well with PWM frequencies between 50 Hz and 100 Hz. The selection is always a trade-off: motors run more smoothly and efficiently at higher frequencies, but control electronics are often more effective and stable at lower ones. In fact, some low-end motors require a strong initial pulse—achievable with low-frequency PWM—to overcome internal friction.
</p>

<p align="justify">
For small hobby motors (typically under 1A), using lower frequencies around 100 Hz tends to provide effective speed control. Higher frequencies may prevent the motor from starting or cause it to spin too fast.
</p>

<p align="justify">
For this project, a PWM frequency of <strong>100 Hz</strong> was selected.
</p>

### Performance Evaluation

<p align="justify">
As an acceptance criterion, the mean square error (MSE) was calculated to evaluate the overall effectiveness of the controller. For the sine wave input, the MSE remained consistently below 1 throughout the test. In the case of the ramp signal, which features less abrupt variation, the MSE stayed below 0.25 — both indicating low error levels.
</p>

<p align="justify">
Controller robustness can also be assessed by observing its response to different types of input signals and external disturbances:
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/72ee57ff-b9d5-4c43-9965-b9c1da2d8edf" alt="Sinusoidal response - motor_control_real" width="600"/>
  <br/>
  <em>Sinusoidal response</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/020a4827-6f40-4a4f-b0ed-40017891402b" alt="Trapezoidal response - motor_control_real" width="600"/>
  <br/>
  <em>Trapezoidal response</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/c540c398-5d19-478d-a218-51a09e52894a" alt="Square response - motor_control_real" width="600"/>
  <br/>
  <em>Square response</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/699a22b5-962a-482c-bddf-e7ad668903fe" alt="Ramp response - motor_control_real" width="600"/>
  <br/>
  <em>Ramp response</em>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/dba5a767-9547-4973-af30-dc7df23b11a2" alt="Response with disturbances - motor_control_real" width="600"/>
  <br/>
  <em>Response with disturbances</em>
</p>

### Bill of Materials & Schematic Diagram

| Component                          | Description                                       |
|------------------------------------|-----------------------------------------------    |
| L298N Motor Driver                 | Dual H-bridge driver for controlling DC motors    |
| MCR2 Brushed DC Motor with Encoder | 6V, 35:1 gear ratio, 176 RPM                      |
| ESP32 Dev Module                   | Microcontroller with Wi-Fi and Bluetooth support  |
| Power Supply                       | 12V regulated supply                              |

<p align="justify">
A single 12V power source is used, connected to the 12V input of the L298N. The onboard voltage regulator is enabled using the jumper. The 5V input pin should not be connected to any external supply, as it already outputs 5V through the onboard regulator. This 5V pin is proposed as a power source to supply the encoder.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/1aca4ea6-2e60-4c63-ba52-060e2850ea32" alt="H-Bridge Configuration" width="40%"/>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/feaa2fc3-0df2-4ed9-ad01-8d1320c6c818" alt="DC Motor with Encoder Pinout" width="40%"/>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/274eed5f-7f6b-49e3-a248-bafb313af231" alt="ESP32 Dev Module Pinout" width="40%"/>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/1ceb4dca-2597-4464-bb8e-01e222bff8b5" alt="Power Supply Configuration" width="40%"/>
</p>

### Execution Guide

<p align="justify">
You will need the <a href="https://docs.arduino.cc/software/ide-v2/tutorials/getting-started/ide-v2-downloading-and-installing/" target="_blank">Arduino IDE</a> and <a href="https://docs.ros.org/en/humble/Installation.html" target="_blank">ROS2 Humble</a> installed on your system. This project was developed and tested on Ubuntu Linux 22.04 (Jammy Jellyfish).
</p>

#### micro-ROS

<p align="justify">
The supported board for micro-ROS bare-metal projects using the Arduino IDE is the <a href="https://docs.espressif.com/projects/arduino-esp32/en/latest/boards/ESP32-DevKitC-1.html" target="_blank">ESP32 Dev Module</a>, using the <a href="https://github.com/espressif/arduino-esp32/releases/tag/2.0.17" target="_blank">Arduino core version 2.0.17</a>.
</p>

<p align="justify">
First, go to the <a href="https://github.com/micro-ROS/micro_ros_arduino/releases/tag/v2.0.6-humble" target="_blank">micro-ROS v2.0.6-humble release page</a> and download the library ZIP file.
</p>

<p align="justify">
Then, include the library in your Arduino project via <code>Sketch → Include Library → Add .ZIP Library...</code>.
</p>

<p align="justify">
Finally, flash the <code>micro_ROS.ino</code> file found in the <code>micro_ros</code> folder of this repository to the ESP32 board.
</p>

#### ROS2

<p align="justify">
To set up the micro-ROS agent, run the provided <code>micro_ros_setup</code> script located in the root of this repository. This script installs all dependencies and builds the agent.
</p>

<p align="justify">
Once the setup is complete and your system has been rebooted or logged back in (to apply serial port permissions), you can start the micro-ROS agent using the following command:
</p>

```bash
ros2 run micro_ros_agent micro_ros_agent serial --dev /dev/ttyUSB0
```

<p align="justify">
After building the <code>motor_control_real</code> package, launch the full system using the command below:
</p>

```bash
ros2 launch motor_control_real motor_control_real.launch.py
```

## Setting Up the Puzzlebot

### Creating the Container

<p align="justify">
<strong>Note:</strong> Make sure <code>docker-compose</code> is installed.
</p>

<p align="justify">
Open a terminal in the root of the cloned repository and run the following command:
</p>

```bash
docker-compose up --build
```

<p align="justify">
This will build a Docker image named <code>puzzlebot_image</code> and create a container named <code>puzzlebot_container</code>, ready to use.
</p>

<p align="justify">
To remove the container along with its associated Docker Compose environment:
</p>

```bash
docker-compose down
```

### Common Container Commands

<p align="justify">
To <strong>start</strong> the container:
</p>

```bash
docker start puzzlebot_container
```

<p align="justify">
To <strong>access</strong> the container:
</p>

```bash
docker exec -it puzzlebot_container bash
```

<p align="justify">
To <strong>stop</strong> the container:
</p>

```bash
docker stop puzzlebot_container
```

<p align="justify">
To <strong>remove</strong> just the container (without Docker Compose):
</p>

```bash
docker rm puzzlebot_container
```

### Testing Mobility with Joystick Teleoperation

<p align="justify">
At this point, you should have completed the hardware connections of the Puzzlebot, flashed the <a href="https://tecmx-my.sharepoint.com/personal/mario_mtz_tec_mx/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fmario%5Fmtz%5Ftec%5Fmx%2FDocuments%2Fpuzzlebot%5Ffirmware&ga=1" target="_blank"><strong>hackerboard firmware</strong></a>, and configured the Jetson using the provided <a href="https://manchesterrobotics-my.sharepoint.com/personal/mario_mtz_manchester-robotics_com/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fmario%5Fmtz%5Fmanchester-robotics%5Fcom%2FDocuments%2FManchester%20Robotics%2FTeaching%20and%20learning%2FCourses%2FCADI%20ROS2%2FCADI%20%2D%20Invierno%2FActivities%2Fjetson%5F2gb%5Fubuntu20%2Ezip" target="_blank">Jetson image</a> and its hotspot network.
</p>

<ol>
  <li>Turn on the Puzzlebot’s power supply.</li>
  <li>Connect to the Puzzlebot's hackerboard Wi-Fi network (SSID and password are shown on the OLED screen).</li>
  <li>Open a web browser and navigate to the default hackerboard IP (commonly <code>192.168.1.1</code>).</li>
  <li>On the configuration page:
    <ul>
      <li>In <strong>Active Modules</strong>, leave only <code>screen</code> enabled and click Save.</li>
      <li>(Optional) Modify SSID and password under <strong>Network Settings</strong> and click Save.</li>
      <li>Under <strong>Motor-Encoder Settings</strong>, select <strong>Wheel Velocities Control Mode</strong> and click Save. This is necessary for joystick teleoperation (later controllers will use other mode).</li>
    </ul>
  </li>
  <li>Click <strong>Change Configuration</strong> and set <code>CommType</code> on <code>ROS parameters</code> to <strong>2</strong> (Serial) in <code>config_live.json</code>. Upload the new configuration to the robot.</li>
  <li>Switch to the Puzzlebot's Jetson Wi-Fi network.</li>
  <li>Connect to the Jetson via SSH:
    <br><code>ssh &lt;username&gt;@&lt;jetson_ip&gt;</code>
  </li>
  <li>Launch the micro-ROS agent on the Jetson:
    <br><code>ros2 launch puzzlebot_ros micro_ros_agent.launch.py</code>
  </li>
  <li>In another terminal, build the workspace of the cloned repository.</li>
  <li>Connect an Xbox One Elite Series controller (or any joystick). You may customize the joystick config files in:
    <ul>
      <li><code>puzzlebot_control/config/joystick_config.yaml</code></li>
      <li><code>puzzlebot_control/config/joystick_teleop.yaml</code></li>
    </ul>
  </li>
  <li>Run the joystick teleoperation launch file:
    <br><code>ros2 launch puzzlebot_bringup joystick_sim_real_teleop_bringup.launch.py</code>
  </li>
</ol>

<p align="justify">
This will also launch a Gazebo simulation acting as a digital twin. It subscribes to the same velocity command topic as the real Puzzlebot, allowing both to move in approximate synchronization.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/2c3a0372-687b-4801-b7a0-92534c67aa9c" alt="Joystick Teleoperation Demo" width="600"/>
</p>

<p align="justify">
In the default control scheme, the left joystick controls linear velocity, and the right joystick controls angular velocity. Holding down the <strong>RB button</strong> is required to send motion commands — otherwise, the robot will remain stationary.
</p>

## Second Stage – Puzzlebot Control (Intelligent Robotics Implementation Course)

<p align="justify">
On the hackerboard configuration page, under <strong>Motor-Encoder Settings</strong>, select <strong>Robot Velocities Control Mode</strong> and click Save.
</p>

### Point-to-Point Open-Loop Controller

<p align="justify">
A basic open-loop controller was implemented to command the Puzzlebot to move between predefined waypoints. The controller publishes linear and angular velocities directly for specific durations.
</p>

<p align="justify">
You can configure a path in <code>puzzlebot_control/config/open_loop_point_controller_config.yaml</code>. Each waypoint should define its <code>x</code> and <code>y</code> coordinates and either a target duration or a pair of speed commands. Two modes are available:
</p>

<ul>
  <li>
    <strong>Time-based mode</strong>: specify <code>total_time</code> per waypoint to automatically compute the required linear and angular velocities.
  </li>
  <li>
    <strong>Speed-based mode</strong>: specify <code>lin_speed</code> and <code>rot_speed</code> per waypoint, and the system will compute the required duration.
  </li>
</ul>

<p align="justify">
In both modes, it is necessary to specify <code>min_linear_speed</code>, <code>max_linear_speed</code>, <code>min_angular_speed</code>, <code>max_angular_speed</code>, and a <code>drift_margin</code>. The drift margin subtracts an extra quantity an extra quantity to each command to improve robustness against drift.
</p>

<p align="justify">
This system is composed of two nodes:
</p>

<p align="justify">
- <code><strong>puzzlebot_control/open_loop_path_generator</strong></code>: processes waypoint configurations and generates motion commands, publishing <code>OpenLoopPose</code> messages containing linear velocity, angular velocity, and execution time for each movement phase.<br>
- <code><strong>puzzlebot_control/open_loop_point_controller</strong></code>: subscribes to <code>OpenLoopPose</code> commands and executes them using a finite state machine, publishing <code>Twist</code> messages to the <code>cmd_vel</code> topic to drive the robot.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/29d18695-e307-49f9-bfb0-5fae29035127" alt="rqt_graph of the point-to-point open-loop control system" width="600"/>
</p>

To execute the controller:

```bash
ros2 launch puzzlebot_control open_loop_point_controller.launch.py
```

<p><strong>Example – Time-based Mode</strong></p>

<pre><code>open_loop_path_generator:
  ros__parameters:
    update_rate: 10.0
    waypoints_json: |
      [
        { "x": 0.0,  "y": 0.25, "total_time": 5.0 },
        { "x": -0.25,"y": 0.0,  "total_time": 5.0 },
        { "x": -0.5, "y": 0.25, "total_time": 5.0 },
        { "x": -0.5, "y": 0.0,  "total_time": 5.0 }
      ]
    min_linear_speed: 0.1
    max_linear_speed: 0.17
    min_angular_speed: 0.1
    max_angular_speed: 1.0
    drift_margin: 0.0

open_loop_point_controller:
  ros__parameters:
    update_rate: 100.0
</code></pre>

<p align="center">
  <img src="https://github.com/user-attachments/assets/dd89c229-a619-41d2-bc90-199b474b8bc5" alt="Point-to-Point Open Loop Control Time-based Mode Demo" width="600"/>
</p>

<p><strong>Example – Speed-based Mode</strong></p>

<pre><code>open_loop_path_generator:
  ros__parameters:
    update_rate: 10.0
    waypoints_json: |
      [
        { "x": 0.6, "y": 0.0,  "lin_speed": 0.15, "rot_speed": 0.8 },
        { "x": 0.6, "y": -0.6, "lin_speed": 0.15, "rot_speed": 0.8 },
        { "x": 0.0, "y": -0.6, "lin_speed": 0.15, "rot_speed": 0.8 },
        { "x": 0.0, "y": 0.0,  "lin_speed": 0.15, "rot_speed": 0.8 }
      ]
    min_linear_speed: 0.1
    max_linear_speed: 0.17
    min_angular_speed: 0.1
    max_angular_speed: 1.0
    drift_margin: 0.0

open_loop_point_controller:
  ros__parameters:
    update_rate: 100.0
</code></pre>

<p align="center">
  <img src="https://github.com/user-attachments/assets/dd801868-afb5-45e8-ad59-7ed309a69d7d" alt="Point-to-Point Open Loop Control Speed-based Mode Demo" width="600"/>
</p>

<p align="justify">

### Point-to-Point PID Controller

<p align="justify">
A PID controller was developed to improve accuracy using feedback from the robot's odometry. 
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/04bee444-6aa4-4b1b-a97d-b6062694aa05" alt="Point-to-Point ṔID Control Demo" width="600"/>
</p>

<p align="justify">
The system consists of three nodes:
</p>

<p align="justify">
- <code><strong>puzzlebot_control/odometry_localization</strong></code>: estimates the robot's pose (x, y, theta) using dead reckoning from wheel encoder data, publishing odometry messages and TF transforms.<br>
- <code><strong>puzzlebot_control/pid_path_generator</strong></code>: serves waypoints through a service interface, providing sequential target positions to the controller upon request.<br>
- <code><strong>puzzlebot_control/pid_point_controller</strong></code>: implements PID control logic to compute velocity commands, minimizing position and heading errors between current pose and target waypoint.
</p>

<p align="justify">
You can configure the system parameters in <code>puzzlebot_control/config/pid_point_controller_config.yaml</code>.
</p>

<p align="justify">
The configuration includes robot physical parameters (wheel base and radius), PID controller gains for both linear and angular velocities, position and heading tolerances for waypoint completion, and velocity limits. Waypoints are defined as a JSON array of x and y coordinates, with distance constraints between consecutive points.
</p>

To launch the controller:

```bash
ros2 launch puzzlebot_control pid_point_controller.launch.py
```

### Multiple Point Navigation with Image Identification

<p align="justify">
A decision-making layer was integrated into the previously developed point-to-point PID navigation algorithm to detect and respond to traffic light colors.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/de52aecf-1987-4300-82f2-15980e17aa91" alt="Traffic Light Navigation System Demo" width="600"/>
</p>

<p align="justify">
The expected behavior follows standard traffic light conventions:
</p>

<ul>
  <li><strong>Green:</strong> Continue normal path execution at full speed.</li>
  <li><strong>Yellow:</strong> Reduce speed significantly until transitioning to red.</li>
  <li><strong>Red:</strong> Stop and remain stationary until a green light is detected.</li>
  <li><strong>No detection:</strong> Stop as a safety measure until valid color detection resumes.</li>
</ul>

<p align="justify">
Visual decision-making capabilities are implemented through two additional nodes that work alongside the existing PID navigation system:
</p>

<p align="justify">
- <code><strong>puzzlebot_vision/color_blob_detection</strong></code>: processes camera images using HSV color filtering and morphological operations to identify red, green, and yellow traffic light blobs, publishing <code>ColorBlobDetection</code> messages containing the largest detected blob's color.<br>
- <code><strong>puzzlebot_behavior/traffic_light_fsm</strong></code>: contains a finite state machine that uses <code>ColorBlobDetection</code> messages to manage traffic light transitions and executes their corresponding actions. For green, it resumes the PID controller and scales its linear velocity control output to 100%, whereas for yellow, it scales the signal to <100% for slower movement; for red and no detection, it stops the PID controller entirely. All of these actions are executed through service calls.
</p>

<p align="justify">
You can configure the system parameters in <code>puzzlebot_bringup/config/traffic_light_fsm_config.yaml</code>.</p>

<p align="justify">
The configuration includes HSV color ranges, image processing and blob detection parameters for traffic light identification, velocity scaling factors for green and yellow states, plus all the standard PID controller and odometry parameters from the previous system.
</p>

To run the system:

```bash
ros2 launch puzzlebot_bringup traffic_light_fsm.launch.py
```

### Line Following

<p align="justify">
A line following layer was added to the previously developed traffic light decision solution.
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/436a6b74-e306-4932-ae79-7fea50fa11d4" alt="Line Following Demo" width="600"/>
</p>

<p align="justify">
Path tracking is accomplished through two additional nodes that work alongside the existing image identification system:
</p>

<p align="justify">
- <code><strong>puzzlebot_vision/line_detection</strong></code>: processes camera images using perspective transformation and image filtering to detect lane markings, then calculates the lane's centroid position and outputs normalized lateral error indicating how far the robot deviates from the lane center.<br>
- <code><strong>puzzlebot_control/line_follow_controller</strong></code>: receives lateral error measurements from the detection node and uses PID control to steer the robot back toward the lane center, maintaining constant forward speed.
</p>

<p align="justify">
You can configure the system parameters in <code>puzzlebot_bringup/config/line_following_config.yaml</code>. 
</p>

<p align="justify">
The configuration includes perspective transformation points for bird's eye view mapping, image processing values for lane detection, constant linear velocity for lane tracking, PID gains for lateral control, timeout value for stopping operation when lane is temporarily lost, steering deadband threshold (a tolerance to reduce small steering oscillations), plus all parameters from the previous system.
</p>

To run the system:

```bash
ros2 launch puzzlebot_bringup line_following.launch.py
```
